{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import re\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a word vector generation model (e.g. Word2Vec) or load pretrained word vectors\n",
    "2. Create an ID's matrix for training set\n",
    "3. Create graph for RNN with LSTM units \n",
    "4. Train\n",
    "5. Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create word vectors using a word vector generation model pretrained using GloVe. The matrix has 400,000 word vectors, each with a dimensionality of 50. <br>\n",
    "\n",
    "Import 2 different data structures: Python list with the 400,000 words & another list with 400,000x50 dimensional embedding matrix that holds all the word vector values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, (400000, 50))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList = np.load('training_data/wordsList.npy')\n",
    "wordsList = wordsList.tolist()\n",
    "wordsList = [word.decode('UTF-8') for word in wordsList]\n",
    "wordVectors = np.load('training_data/wordVectors.npy')\n",
    "\n",
    "len(wordsList), wordVectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9327  ,  1.0421  , -0.78515 ,  0.91033 ,  0.22711 , -0.62158 ,\n",
       "       -1.6493  ,  0.07686 , -0.5868  ,  0.058831,  0.35628 ,  0.68916 ,\n",
       "       -0.50598 ,  0.70473 ,  1.2664  , -0.40031 , -0.020687,  0.80863 ,\n",
       "       -0.90566 , -0.074054, -0.87675 , -0.6291  , -0.12685 ,  0.11524 ,\n",
       "       -0.55685 , -1.6826  , -0.26291 ,  0.22632 ,  0.713   , -1.0828  ,\n",
       "        2.1231  ,  0.49869 ,  0.066711, -0.48226 , -0.17897 ,  0.47699 ,\n",
       "        0.16384 ,  0.16537 , -0.11506 , -0.15962 , -0.94926 , -0.42833 ,\n",
       "       -0.59457 ,  1.3566  , -0.27506 ,  0.19918 , -0.36008 ,  0.55667 ,\n",
       "       -0.70315 ,  0.17157 ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search word list for a word, \n",
    "# then access its vector via the embedding matrix\n",
    "baseballIndex = wordsList.index('baseball')\n",
    "wordVectors[baseballIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take an input sentence and construct its vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,), array([    41,    804, 201534,   1005,     15,   7446,      5,  13767,\n",
       "             0,      0], dtype=int32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of sentence\n",
    "maxSeqLength = 10\n",
    "\n",
    "# Dimensions for each word vector\n",
    "numDimensions = 300\n",
    "\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"i\")\n",
    "firstSentence[1] = wordsList.index(\"thought\")\n",
    "firstSentence[2] = wordsList.index(\"the\")\n",
    "firstSentence[3] = wordsList.index(\"movie\")\n",
    "firstSentence[4] = wordsList.index(\"was\")\n",
    "firstSentence[5] = wordsList.index(\"incredible\")\n",
    "firstSentence[6] = wordsList.index(\"and\")\n",
    "firstSentence[7] = wordsList.index(\"inspiring\")\n",
    "\n",
    "# firstSentence[8] and firstSentence[9] are 0\n",
    "firstSentence.shape, firstSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get word vectors by TF's embedding lookup function, which takes: embedding matrix (wordVectors) and another matrix for the ids of each of the words (firstSentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "# 10x50 output, with 50 dimensional word vec for each of 10 words\n",
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors, firstSentence).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the total and average number of words in each revie (pos/neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveFiles = []\n",
    "for f in listdir('training_data/positiveReviews/'):\n",
    "    if isfile(join('training_data/positiveReviews/', f)):\n",
    "        positiveFiles.append('training_data/positiveReviews/' + f)\n",
    "        \n",
    "negativeFiles = []\n",
    "for f in listdir('training_data/negativeReviews/'):\n",
    "    if isfile(join('training_data/negativeReviews/', f)):\n",
    "        negativeFiles.append('training_data/negativeReviews/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files: 25000\n",
      "Total number of words: 5844680\n",
      "Average number of words in files: 233.7872\n"
     ]
    }
   ],
   "source": [
    "numWords = []\n",
    "for pf in positiveFiles:\n",
    "    with open(pf, \"r\", encoding=\"utf-8\") as f:\n",
    "        line = f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)\n",
    "\n",
    "for pf in negativeFiles:\n",
    "    with open(pf, \"r\", encoding=\"utf-8\") as f:\n",
    "        line = f.readline()\n",
    "        counter = len(line.split())\n",
    "        numWords.append(counter)\n",
    "\n",
    "numFiles = len(numWords)\n",
    "\n",
    "print(\"Total number of files: {}\".format(numFiles))\n",
    "print(\"Total number of words: {}\".format(sum(numWords)))\n",
    "print(\"Average number of words in files: {}\".format(sum(numWords)/len(numWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185cd71898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data\n",
    "plt.hist(numWords, 50)\n",
    "plt.xlabel('Sequence length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1500, 0, 7500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the histogram and average of words per file, most reviews will have < 250 words, which is the max sequence length to set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSeqLength = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a single file and transform it into an ids matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is easily the most underrated film inn the Brooks cannon. Sure, its flawed. It does not give a realistic view of homelessness (unlike, say, how Citizen Kane gave a realistic view of lounge singers, or Titanic gave a realistic view of Italians YOU IDIOTS). Many of the jokes fall flat. But still, this film is very lovable in a way many comedies are not, and to pull that off in a story about some of the most traditionally reviled members of society is truly impressive. Its not The Fisher King, but its not crap, either. My only complaint is that Brooks should have cast someone else in the lead (I love Mel as a Director and Writer, not so much as a lead).\n"
     ]
    }
   ],
   "source": [
    "# Example single file\n",
    "fname = positiveFiles[3]\n",
    "with open(fname) as f:\n",
    "    [print(lines) for lines in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert file into an ids matrix\n",
    "# Remove punctuations, parantheses, question marks, etc. \n",
    "# Only leave alphanumeric characters\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "\n",
    "def cleanSentences(string):\n",
    "    string = string.lower().replace(\" <br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstFile = np.zeros((maxSeqLength), dtype=\"int32\")\n",
    "with open(fname) as f:\n",
    "    indexCounter = 0\n",
    "    line = f.readline()\n",
    "    cleanedLine = cleanSentences(line)\n",
    "    split = cleanedLine.split()\n",
    "    for word in split:\n",
    "        try:\n",
    "            firstFile[indexCounter] = wordsList.index(word)\n",
    "        except ValueError:\n",
    "            # Vector for unknown words\n",
    "            firstFile[indexCounter] = 399999\n",
    "        indexCounter = indexCounter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for all the reviews. Load in the training set and integerize it to get a 250000x250 matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "# fileCounter = 0\n",
    "# for pf in positiveFiles:\n",
    "#     with open(pf, \"r\") as f:\n",
    "#         indexCounter = 0\n",
    "#         line=f.readline()\n",
    "#         cleanedLine = cleanSentences(line)\n",
    "#         split = cleanedLine.split()\n",
    "#         for word in split:\n",
    "#             try:\n",
    "#                 ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#             except ValueError:\n",
    "#                 ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#             indexCounter = indexCounter + 1\n",
    "#             if indexCounter >= maxSeqLength:\n",
    "#                 break\n",
    "#         fileCounter = fileCounter + 1 \n",
    "\n",
    "# for nf in negativeFiles:\n",
    "#     with open(nf, \"r\") as f:\n",
    "#         indexCounter = 0\n",
    "#         line=f.readline()\n",
    "#         cleanedLine = cleanSentences(line)\n",
    "#         split = cleanedLine.split()\n",
    "#         for word in split:\n",
    "#             try:\n",
    "#                 ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#             except ValueError:\n",
    "#                 ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "#             indexCounter = indexCounter + 1\n",
    "#             if indexCounter >= maxSeqLength:\n",
    "#                 break\n",
    "#         fileCounter = fileCounter + 1 \n",
    "# #Pass into embedding function and see if it evaluates. \n",
    "\n",
    "# np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 250)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load instead of re-generating\n",
    "ids = np.load('training_data/idsMatrix.npy')\n",
    "ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use during training later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        if (i % 2 == 0):\n",
    "            num = randint(1, 11499)\n",
    "            labels.append([1, 0])\n",
    "        else:\n",
    "            num = randint(13499, 24999)\n",
    "            labels.append([0, 1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels\n",
    "\n",
    "def getTrestBatch():\n",
    "    labels = []\n",
    "    arr = np.zeros([batchSize, maxSeqLength])\n",
    "    for i in range(batchSize):\n",
    "        num = randint(11499, 13499)\n",
    "        if (num <= 12499):\n",
    "            labels.append([1, 0])\n",
    "        else:\n",
    "            labels.append([0, 1])\n",
    "        arr[i] = ids[num-1:num]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TensorFlow graph: Define hyperparameters (batch size, number of LSTM units, number of output classes, and number of training iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 24\n",
    "lstmUnits = 64\n",
    "numClasses = 2  # Pos or neg \n",
    "iterations = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify 2 placeholders, for the inputs into the network and for the labels. Important: understand their dimensionalities. <br>\n",
    "\n",
    "The labels placeholder represents a set of value (either [1,0] or [0,1]) depending on whether each training example is positive or negative. Each row in the integerized input placeholder represents the representation of each training example that we include in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the tf.nn.lookup() function to get word vectors. That returns a 3D Tensor of dimensionality batch size by max sequence length by word vector dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup/Identity:0' shape=(24, 250, 50) dtype=float32>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),\n",
    "                  dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors, input_data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the input into an LSTM network. Call the tf.nn.rnn_cell.BasicLSTMCell function. Takes in an integer for the number of LSTM units we want. This is a hyperparameter. Then wrap the LSTM cell in a dropout layer to prevent overfitting. <br>\n",
    "\n",
    "Then, feed the LSTM cell and 3D tensor full of input data into the function tf.nn.dynamic_rnn. It unrolls the whole network and create a pathway for the data to flow through the RNN graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmCell = tf.nn.rnn_cell.LSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First output of the dynamic RNN function: the last hidden state vector. This vector will be reshaped and multiplied by a final weight matrix and bias term to get the final output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
