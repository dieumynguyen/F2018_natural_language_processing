{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: for unseen words, baseline should output most frequent tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Training Data:</b>\n",
    "\n",
    "POS-tagged data from Berkeley Restaurant corpus. ~15,000 sentences in corpus. \n",
    "\n",
    "Assume: 1) POS tagset is closed. 2) New words will occur in testset. \n",
    "\n",
    "File format: Sentences are arranged as 1 word per line with blank line separating the sentences. Columns are tab separated. 1st col is word position, 2nd col is word, and 3rd col is POS tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fname = 'training_set_shuffled.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_fname, 'r') as file:\n",
    "    training_data = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Evaluation:</b>\n",
    "\n",
    "Basic script is provided and calculates overall accuracy compared to a gold standard eval set. \n",
    "\n",
    "``` python eval-pos.py  gold-file system-file ```\n",
    "\n",
    "Produce a confusion matrix for more useful tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Task: Build a probabilistic tagger</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>1) Baseline system:</b> \n",
    "Implement a \"most frequent tag\" system. Given counts from training data, the tagger should simply assign to each input word the tag that it was most frequently assigned to in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_pos_count(training_data):\n",
    "    '''\n",
    "    Given a training set, create a list of lists as lookup table.\n",
    "    Each inside list is a word, its POS, and the frequency of this pairing.\n",
    "    '''\n",
    "    \n",
    "    # Create list of tuple: (word, POS)\n",
    "    tups_list = []\n",
    "    for line in training_data:\n",
    "        if line != '\\n':\n",
    "            split_line = line.strip().split('\\t')\n",
    "            word_pos = split_line[1], split_line[2]\n",
    "            tups_list.append(word_pos)\n",
    "\n",
    "    # Get count of each unique tuple\n",
    "    count_set = dict((x, tups_list.count(x)) for x in set(tups_list))\n",
    "\n",
    "    # Create list of [word, POS, count]\n",
    "    word_pos_count = []\n",
    "    for k in count_set.keys():\n",
    "        k_list = list(k)\n",
    "        k_list.append(count_set[k])\n",
    "        word_pos_count.append(k_list)\n",
    "    \n",
    "    return word_pos_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent_tag(word_pos_count, input_word):\n",
    "    '''\n",
    "    Given word_pos_count from training data & an input word, \n",
    "    get the most frequent POS by \n",
    "    calling the function get_word_pos_count() to get the lookup table\n",
    "    and match input word to most frequent POS.\n",
    "    \n",
    "    Return most frequent tag for that word.\n",
    "    '''\n",
    "    \n",
    "    # Get word_pos_count lookup table\n",
    "    # word_pos_count = get_word_pos_count(training_data)\n",
    "    \n",
    "    # Get max word_pos_count's tag\n",
    "    counts = []\n",
    "    for i, word_pos in enumerate(word_pos_count):\n",
    "        counts.append(word_pos_count[i][2])\n",
    "    most_freq = word_pos_count[np.argmax(counts)][1]\n",
    "    \n",
    "    # Matching input word to possible word-tag-count lists\n",
    "    matching_l = []\n",
    "    for l in word_pos_count:    \n",
    "        if l[0] == input_word:\n",
    "            matching_l.append(l)\n",
    "\n",
    "    # print('{} \\n'.format(matching_l))\n",
    "\n",
    "    # Find most frequent POS tag\n",
    "    most_frequent_tag = ''\n",
    "    # Dealing with unseen words (matching_l: []), assign POS 'UNK'\n",
    "    if len(matching_l) == 0:\n",
    "        most_frequent_tag = most_freq\n",
    "    else:\n",
    "        # Find max count and tag that POS to word\n",
    "        max_count = matching_l[0][2] # Temporary max\n",
    "        for match in matching_l:\n",
    "            if match[2] > max_count:\n",
    "                most_frequent_tag = match[1]\n",
    "            elif match[2] == max_count:\n",
    "                most_frequent_tag = match[1]\n",
    "                \n",
    "    return most_frequent_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "input_word = 'food'\n",
    "get_most_frequent_tag(word_pos_count, input_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the short test file\n",
    "with open('test_set_shuffled.txt', 'r') as test_file:\n",
    "    test_data = test_file.readlines()\n",
    "\n",
    "baseline_tags = []\n",
    "for line in test_data:\n",
    "    if line != \"\\n\":\n",
    "        line = line.split()\n",
    "        word = line[1]\n",
    "        tag = get_most_frequent_tag(word_pos_count, word)\n",
    "        baseline_tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MD',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " '.',\n",
       " 'UH',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'UH',\n",
       " '.',\n",
       " 'UH',\n",
       " 'RB',\n",
       " 'DT',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'PRP',\n",
       " 'VBN',\n",
       " 'NN',\n",
       " 'VB',\n",
       " 'VBG',\n",
       " '.',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'EX',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'TO',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'UH',\n",
       " 'NN',\n",
       " 'JJR',\n",
       " 'UH',\n",
       " '.',\n",
       " 'WP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'HYPH',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'MD',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'FW',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'WDT',\n",
       " 'JJ',\n",
       " 'CD',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'UH',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'NNP',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'NN',\n",
       " 'PDT',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'CD',\n",
       " 'TO',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'UH',\n",
       " 'UH',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'WDT',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'CC',\n",
       " 'WDT',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'RB',\n",
       " 'UH',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'UH',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'POS',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'WDT',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'FW',\n",
       " 'HYPH',\n",
       " 'FW',\n",
       " '.',\n",
       " 'WDT',\n",
       " 'POS',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'VBZ',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'VBG',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'UH',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'RP',\n",
       " 'UH',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'WP',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'WDT',\n",
       " 'POS',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'WP',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'RB',\n",
       " '.',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'UH',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'RB',\n",
       " 'RB',\n",
       " '.',\n",
       " 'MD',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'EX',\n",
       " 'RB',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'WRB',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'WP',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'PDT',\n",
       " 'RB',\n",
       " '.',\n",
       " 'UH',\n",
       " 'RB',\n",
       " 'DT',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'PRP',\n",
       " 'VBN',\n",
       " 'NN',\n",
       " 'VB',\n",
       " 'VBG',\n",
       " '.',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'HYPH',\n",
       " 'NN',\n",
       " 'HYPH',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VBZ',\n",
       " 'PRP',\n",
       " 'UH',\n",
       " 'UH',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJR',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'UH',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VBP',\n",
       " 'EX',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'UH',\n",
       " 'CD',\n",
       " 'CD',\n",
       " 'CD',\n",
       " 'TO',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'JJS',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'UH',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'WP',\n",
       " 'IN',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'UH',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VBZ',\n",
       " 'NN',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'VB',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBG',\n",
       " 'RP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'NN',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'WP',\n",
       " 'MD',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'VBN',\n",
       " '.',\n",
       " 'WP',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'UH',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'RP',\n",
       " 'CD',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'POS',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'WDT',\n",
       " 'POS',\n",
       " 'IN',\n",
       " 'JJS',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'JJS',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'PRP$',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " '.',\n",
       " 'MD',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'RP',\n",
       " '.',\n",
       " 'WDT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VB',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'UH',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJR',\n",
       " 'NN',\n",
       " '.',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'POS',\n",
       " '.',\n",
       " 'WP',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBG',\n",
       " 'RP',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NN',\n",
       " '.',\n",
       " 'NN',\n",
       " 'HYPH',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'HYPH',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'POS',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'WP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'POS',\n",
       " 'VBG',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'UH',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'NN',\n",
       " 'UH',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'CC',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'PRP',\n",
       " ...]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = ''\n",
    "for line in test_data:\n",
    "    if line != '\\n':\n",
    "        split_line = line.strip().split('\\t')\n",
    "        word = split_line[1]\n",
    "        tag = get_most_frequent_tag(word_pos_count, word)\n",
    "        # print(word, tag)\n",
    "        new_file += '{}\\t{}\\t{}\\n'.format(split_line[0], word, tag)\n",
    "    elif line == '\\n':\n",
    "        new_file += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write new_file with POs tags to a file\n",
    "with open('baseline_test.txt', 'w') as baseline:\n",
    "    pass # Empty content before writing\n",
    "    baseline.write(new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>2) Viterbi algorithm:</b>  \n",
    "\n",
    "Implement Viterbi with a bigram-based approach (only need previous to infer current). \n",
    "1. Extract required counts from training data to generate required probability estimates for model.\n",
    "2. Deal with unknown words in some sensible way: UNK\n",
    "3. Do some form of smoothing for the bigram tag model: Add 1\n",
    "4. Implement Viterbi decoder.\n",
    "5. Evaluate performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Step 1. Create state transition probability matrix</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\ti\\tPRP\\n'"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_train = training_data[0:7]\n",
    "short_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PRP'], 1, ['PRP', 'MD', 'VB', 'TO', 'VB', 'IN', 'DT'])"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create ordered list of POS & observed tokens\n",
    "pos_array = []\n",
    "token_array = []\n",
    "\n",
    "# Get list of POS that are at position 1 in sentences\n",
    "init_array = []\n",
    "\n",
    "num_sentences = 0\n",
    "\n",
    "for line in short_train:\n",
    "    if line != '\\n':\n",
    "        split_line = line.strip().split('\\t')\n",
    "        pos = split_line[2]\n",
    "        token = split_line[1]\n",
    "        pos_array.append(pos)\n",
    "        token_array.append(token)\n",
    "        \n",
    "        if split_line[0] == '1':\n",
    "            init_array.append(split_line[2])\n",
    "            num_sentences += 1\n",
    "            \n",
    "init_array, num_sentences, pos_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>followed:</th>\n",
       "      <th>DT</th>\n",
       "      <th>IN</th>\n",
       "      <th>MD</th>\n",
       "      <th>PRP</th>\n",
       "      <th>TO</th>\n",
       "      <th>VB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>given:</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VB</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "followed:   DT   IN   MD  PRP   TO   VB\n",
       "given:                                 \n",
       "DT         1.0  0.0  0.0  0.0  0.0  0.0\n",
       "IN         0.0  1.0  0.0  0.0  0.0  0.0\n",
       "MD         0.0  0.0  1.0  0.0  0.0  0.0\n",
       "PRP        0.0  0.0  0.0  1.0  0.0  0.0\n",
       "TO         0.0  0.0  0.0  0.0  1.0  0.0\n",
       "VB         0.0  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix = pd.crosstab(pd.Series(pos_array[:], name='given:'),\n",
    "                                pd.Series(pos_array[:], name='followed:'), \n",
    "                                normalize=0)\n",
    "\n",
    "transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-775-f7d368e665f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{0:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-775-f7d368e665f6>\u001b[0m in \u001b[0;36mtransition_matrix\u001b[0;34m(transitions)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#now convert to probabilities:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "def transition_matrix(transitions):\n",
    "    n = len(set(transitions)) #number of states\n",
    "\n",
    "    M = [[0]*n for _ in range(n)]\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        M[i][j] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    return M\n",
    "\n",
    "m = transition_matrix(pos_array)\n",
    "for row in m: print(' '.join('{0:.2f}'.format(x) for x in row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition_matrix_np = transition_matrix.reset_index().values\n",
    "# transition_matrix_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Step 2. Create emission / observation likelihood matrix</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word:   'd    a   go    i  like   to\n",
      "tag:                                \n",
      "DT     0.0  1.0  0.0  0.0   0.0  0.0\n",
      "IN     0.0  0.0  0.0  0.0   0.0  1.0\n",
      "MD     1.0  0.0  0.0  0.0   0.0  0.0\n",
      "PRP    0.0  0.0  0.0  1.0   0.0  0.0\n",
      "TO     0.0  0.0  0.0  0.0   0.0  1.0\n",
      "VB     0.0  0.0  0.5  0.0   0.5  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_matrix = pd.crosstab(pd.Series(pos_array[:], name=\"tag:\"),\n",
    "                              pd.Series(token_array, name=\"word:\"), \n",
    "                              normalize=0)\n",
    "print(emission_matrix)\n",
    "emission_matrix.at['VB','go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_matrix_np = emission_matrix.reset_index().values\n",
    "# emission_matrix_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\***** smooth with Laplace add-1 smoothing for emission probs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Step 3. Create initial probability vector: prob of a POS follwing start of sentence</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MD': 0.0, 'PRP': 1.0, 'TO': 0.0, 'VB': 0.0}"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_vector = {}\n",
    "for pos in list(set(pos_array)):\n",
    "    init_vector[pos] = init_array.count(pos) / num_sentences\n",
    "init_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Step 3. Create table where columns are observations (all sentences in order) and rows are possible hidden states. \n",
    "    \n",
    "Step 4. Sweep through table and find max prob and path. </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "NN\n",
      "PRP\n",
      ".\n",
      "TO\n",
      "MD\n",
      "IN\n",
      "VB\n",
      "JJ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.66666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = ['i', \"'d\", 'like', 'food'] # emissions/seq - aka x\n",
    "Q =  list(set(pos_array)) # set of states\n",
    "'''\n",
    "Given a sequence of emissions, return the most probably path and \n",
    "its joint probability.\n",
    "'''\n",
    "\n",
    "nrow, ncol = len(Q), len(x)+1\n",
    "mat = np.zeros(shape=(nrow, ncol), dtype=float) # prob table\n",
    "matTb = np.zeros(shape=(nrow, ncol), dtype=int) # backtrace\n",
    "\n",
    "# Fill in 1st column of mat: P(POS|start) * P(word|POS)\n",
    "start_col = []\n",
    "for i, pos in enumerate(Q):\n",
    "    print(pos)\n",
    "    mat[i, 0] = init_vector[pos] * emission_matrix.at[pos, input_seq[0]]\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Fill in the rest of mat table\n",
    "for j, token in enumerate(input_seq):\n",
    "#     print(j, token)    \n",
    "    one_token_all_states = []\n",
    "    for i, pos in enumerate(Q):\n",
    "        # Probability of first word \"i\" at each pos = mat[i, 0] * P(word|POS)\n",
    "        # Starts filling in mat at j=1 now\n",
    "        \n",
    "        one_token_all_states.append(start_col[i] * emission_matrix.at[pos, token])\n",
    "        \n",
    "        # mat[i, j+1] = mat[i, j] * emission_matrix.at[pos, token]\n",
    "#         for i2, pos2 in enumerate(Q):\n",
    "            \n",
    "#     * emission_matrix.at[pos, x[i]]\n",
    "\n",
    "#     emission_matrix[i, x[0]] * init_vector[i]\n",
    "    print(one_token_all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on a test file\n",
    "with open('testfile.txt', 'w') as the_file:\n",
    "    pass # Empty content before writing\n",
    "    the_file.write(\"1\\ti\\n\")\n",
    "    the_file.write(\"2\\t'd\\n\")\n",
    "    the_file.write(\"3\\tlike\\n\")\n",
    "    the_file.write(\"4\\tzachary\\n\")\n",
    "    the_file.write(\"5\\t's\\n\")\n",
    "    the_file.write(\"6\\ta\\n\")\n",
    "    the_file.write(\"7\\t-\\n\")\n",
    "    the_file.write(\"8\\tla\\n\")\n",
    "    the_file.write(\"9\\t-\\n\")\n",
    "    the_file.write(\"10\\tcarte\\n\")\n",
    "    the_file.write(\"11\\t.\\n\")\n",
    "    the_file.write('\\n')\n",
    "    the_file.write(\"1\\ti\\n\")\n",
    "    the_file.write(\"2\\tunseen\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize needed?\n",
    "# input_sentence = \"i'd i've zachary's a-la-carte at 11 am.\"\n",
    "\n",
    "# split_sentence = word_tokenize(input_sentence)\n",
    "# print(split_sentence)\n",
    "\n",
    "# for token_i, token in enumerate(split_sentence):\n",
    "#     if ('-' in token):\n",
    "#         split_token = re.split('(\\W)', token)\n",
    "#         print(split_token)\n",
    "#         split_sentence[token_i] = split_token\n",
    "        \n",
    "# list(np.hstack(split_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
